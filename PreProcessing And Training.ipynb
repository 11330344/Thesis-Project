{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Dk7bnZd7eAZ2rWOWuHSX028vbxcqNQaG","authorship_tag":"ABX9TyOxMHvQPUas95Co2103GQZc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uui5B9Ov-jbz","executionInfo":{"status":"ok","timestamp":1713625304395,"user_tz":-180,"elapsed":106517,"user":{"displayName":"Ali Dayekh","userId":"07648341246926446703"}},"outputId":"5c9ba1e2-6a91-48a1-953d-7fe7b4b558dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","164/164 [==============================] - 9s 19ms/step - loss: 1.3536 - accuracy: 0.3443 - val_loss: 1.3290 - val_accuracy: 0.3774\n","Epoch 2/25\n","164/164 [==============================] - 2s 12ms/step - loss: 1.2942 - accuracy: 0.4088 - val_loss: 1.2266 - val_accuracy: 0.4764\n","Epoch 3/25\n","164/164 [==============================] - 2s 11ms/step - loss: 1.2161 - accuracy: 0.4713 - val_loss: 1.1573 - val_accuracy: 0.5137\n","Epoch 4/25\n","164/164 [==============================] - 2s 11ms/step - loss: 1.1593 - accuracy: 0.5027 - val_loss: 1.1089 - val_accuracy: 0.5301\n","Epoch 5/25\n","164/164 [==============================] - 2s 11ms/step - loss: 1.1152 - accuracy: 0.5232 - val_loss: 1.0726 - val_accuracy: 0.5490\n","Epoch 6/25\n","164/164 [==============================] - 2s 11ms/step - loss: 1.0800 - accuracy: 0.5410 - val_loss: 1.0447 - val_accuracy: 0.5702\n","Epoch 7/25\n","164/164 [==============================] - 2s 12ms/step - loss: 1.0509 - accuracy: 0.5561 - val_loss: 1.0165 - val_accuracy: 0.5742\n","Epoch 8/25\n","164/164 [==============================] - 2s 13ms/step - loss: 1.0258 - accuracy: 0.5674 - val_loss: 0.9976 - val_accuracy: 0.5852\n","Epoch 9/25\n","164/164 [==============================] - 2s 12ms/step - loss: 1.0028 - accuracy: 0.5744 - val_loss: 0.9833 - val_accuracy: 0.5862\n","Epoch 10/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.9860 - accuracy: 0.5833 - val_loss: 0.9770 - val_accuracy: 0.5969\n","Epoch 11/25\n","164/164 [==============================] - 2s 12ms/step - loss: 0.9668 - accuracy: 0.5937 - val_loss: 0.9599 - val_accuracy: 0.6043\n","Epoch 12/25\n","164/164 [==============================] - 2s 12ms/step - loss: 0.9487 - accuracy: 0.6017 - val_loss: 0.9497 - val_accuracy: 0.6102\n","Epoch 13/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.9313 - accuracy: 0.6135 - val_loss: 0.9394 - val_accuracy: 0.6203\n","Epoch 14/25\n","164/164 [==============================] - 2s 12ms/step - loss: 0.9190 - accuracy: 0.6186 - val_loss: 0.9275 - val_accuracy: 0.6198\n","Epoch 15/25\n","164/164 [==============================] - 2s 12ms/step - loss: 0.9026 - accuracy: 0.6252 - val_loss: 0.9139 - val_accuracy: 0.6331\n","Epoch 16/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.8888 - accuracy: 0.6352 - val_loss: 0.9111 - val_accuracy: 0.6299\n","Epoch 17/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.8760 - accuracy: 0.6410 - val_loss: 0.9232 - val_accuracy: 0.6199\n","Epoch 18/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.8639 - accuracy: 0.6434 - val_loss: 0.8972 - val_accuracy: 0.6404\n","Epoch 19/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.8500 - accuracy: 0.6522 - val_loss: 0.9000 - val_accuracy: 0.6360\n","Epoch 20/25\n","164/164 [==============================] - 2s 10ms/step - loss: 0.8396 - accuracy: 0.6576 - val_loss: 0.9136 - val_accuracy: 0.6289\n","Epoch 21/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.8299 - accuracy: 0.6616 - val_loss: 0.9053 - val_accuracy: 0.6289\n","Epoch 22/25\n","164/164 [==============================] - 2s 13ms/step - loss: 0.8190 - accuracy: 0.6700 - val_loss: 0.8784 - val_accuracy: 0.6461\n","Epoch 23/25\n","164/164 [==============================] - 2s 12ms/step - loss: 0.8087 - accuracy: 0.6718 - val_loss: 0.8745 - val_accuracy: 0.6499\n","Epoch 24/25\n","164/164 [==============================] - 2s 11ms/step - loss: 0.7951 - accuracy: 0.6782 - val_loss: 0.8765 - val_accuracy: 0.6468\n","Epoch 25/25\n","164/164 [==============================] - 2s 10ms/step - loss: 0.7835 - accuracy: 0.6845 - val_loss: 0.8660 - val_accuracy: 0.6545\n","164/164 [==============================] - 1s 5ms/step - loss: 0.8660 - accuracy: 0.6545\n","Accuracy on test set: 65.45%\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","# Load the data and preprocess it\n","df = pd.read_csv('/content/drive/MyDrive/Thesis New/fer2013.csv')\n","\n","# Remove disgust and surprise emotions\n","df = df[(df['emotion'] != 1) & (df['emotion'] != 5)]\n","\n","pixels = df['pixels'].tolist()\n","X = np.array([np.fromstring(pixel, dtype=int, sep=' ') for pixel in pixels])\n","X = X.reshape(-1, 48, 48, 1) / 255.0  # Normalize pixel values\n","y = df['emotion'].values\n","\n","# Perform one-hot encoding\n","encoder = LabelEncoder()\n","y = encoder.fit_transform(y)\n","y = pd.get_dummies(y).values  # Convert to one-hot encoding\n","\n","# Ensure the correct number of output units in the model\n","num_classes = y.shape[1]  # Get the number of classes from one-hot encoding\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Build the CNN model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))  # Output layer with num_classes units\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.0001)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, batch_size=128, epochs=25, validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n","\n","# Save the model architecture as a JSON file\n","model_json = model.to_json()\n","with open('model.json', 'w') as json_file:\n","    json_file.write(model_json)\n","\n","# Save the model weights as an HDF5 file\n","model.save_weights('model.h5')\n"]}]}